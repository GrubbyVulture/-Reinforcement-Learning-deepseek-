{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "好的，用户问的是树下一只猴，树上骑个猴，问一共几只。首先，我需要确认这两个场景。树下一只猴子，树上可能有骑着的猴子，但通常骑猴子的人不会在树上，所以可能只是树下一只。然后，总共有两只猴子。所以答案应该是2。\n",
      "</think>\n",
      "\n",
      "<answer>\n",
      "2\n",
      "</answer>\n"
     ]
    }
   ],
   "source": [
    "# checkposint500_v2\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8222/v1\",  # ← 补上 http://\n",
    "    api_key=\"nn\"                          # vLLM 不校验，随意\n",
    ")\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "按照如下格式生成：\n",
    "<think>\n",
    "...\n",
    "</think>\n",
    "<answer>\n",
    "...\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"qwen\",  # 必须和 vLLM 启动时 --served-model-name 完全一致\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": \"树下一只猴？树上骑个猴？请问一共几只猴？\"}\n",
    "    ],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "好的，我来算一下。树下一只猴子，树上骑着一只猴子，所以总共是两只。所以答案应该是2只。\n",
      "</think>\n",
      "<answer>\n",
      "2\n",
      "</answer>\n"
     ]
    }
   ],
   "source": [
    "# checkposint1000_v2\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8222/v1\",  # ← 补上 http://\n",
    "    api_key=\"nn\"                          # vLLM 不校验，随意\n",
    ")\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "按照如下格式生成：\n",
    "<think>\n",
    "...\n",
    "</think>\n",
    "<answer>\n",
    "...\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"qwen\",  # 必须和 vLLM 启动时 --served-model-name 完全一致\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": \"树下一只猴？树上骑个猴？请问一共几只猴？\"}\n",
    "    ],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "好的，首先确定题目中的情况：树下有一只猴，树上有一只骑着的猴。总共是两只猴子。所以答案应该是2只。\n",
      "</think>\n",
      "<answer>\n",
      "2\n",
      "</answer>\n"
     ]
    }
   ],
   "source": [
    "# checkposint1500_v2\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8222/v1\",  # ← 补上 http://\n",
    "    api_key=\"nn\"                          # vLLM 不校验，随意\n",
    ")\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "按照如下格式生成：\n",
    "<think>\n",
    "...\n",
    "</think>\n",
    "<answer>\n",
    "...\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"qwen\",  # 必须和 vLLM 启动时 --served-model-name 完全一致\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": \"树下一只猴？树上骑个猴？请问一共几只猴？\"}\n",
    "    ],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "好的，首先确定总共的猴子数量。树下有一只猴，树上有一只骑着的猴。所以总共是两只猴子对吧？不过别急，别看错了哦，别急点。</answer>\n",
      "</think>\n",
      "<answer>\n",
      "2\n",
      "</answer>\n"
     ]
    }
   ],
   "source": [
    "# checkposint2000_v2\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8222/v1\",  # ← 补上 http://\n",
    "    api_key=\"nn\"                          # vLLM 不校验，随意\n",
    ")\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "按照如下格式生成：\n",
    "<think>\n",
    "...\n",
    "</think>\n",
    "<answer>\n",
    "...\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"qwen\",  # 必须和 vLLM 启动时 --served-model-name 完全一致\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": \"树下一只猴？树上骑个猴？请问一共几只猴？\"}\n",
    "    ],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "嗯，我现在要解决这个问题：“树下一只猴？树上骑个猴？请问一共几只猴？”首先，我需要仔细理解题目中的各个部分。\n",
      "\n",
      "首先，“树下一只”指的是在树下有一只猴子。然后“树上骑个”可能是指在树上骑着一只猴子。那这两个动作都是在同一个地方吗？比如，可能是一只猴子在树下，然后又骑着一只猴子在树上，所以总共有两只？\n",
      "\n",
      "不过，这里要注意的是，是否是同一只猴子被同时骑在树上和在树下。比如，可能是一只猴子在树下，然后骑着它自己，所以总共有两只？\n",
      "\n",
      "所以答案应该是两只？\n",
      "</answer>\n",
      "</think>\n",
      "\n",
      "<answer>\n",
      "两只。\n",
      "</answer>\n"
     ]
    }
   ],
   "source": [
    "# checkposint400_v3\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8222/v1\",  # ← 补上 http://\n",
    "    api_key=\"nn\"                          # vLLM 不校验，随意\n",
    ")\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "按照如下格式生成：\n",
    "<think>\n",
    "...\n",
    "</think>\n",
    "<answer>\n",
    "...\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"qwen\",  # 必须和 vLLM 启动时 --served-model-name 完全一致\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": \"树下一只猴？树上骑个猴？请问一共几只猴？\"}\n",
    "    ],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "嗯，算出了 100 一只。\n",
      "\n",
      "</answer>\n",
      "</think>\n",
      "\n",
      "答案：100 一只。\n"
     ]
    }
   ],
   "source": [
    "# checkposint800_v3\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8222/v1\",  # ← 补上 http://\n",
    "    api_key=\"nn\"                          # vLLM 不校验，随意\n",
    ")\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "按照如下格式生成：\n",
    "<think>\n",
    "...\n",
    "</think>\n",
    "<answer>\n",
    "...\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"qwen\",  # 必须和 vLLM 启动时 --served-model-name 完全一致\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": \"树下一只猴？树上骑个猴？请问一共几只猴？\"}\n",
    "    ],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gzy)",
   "language": "python",
   "name": "gzy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
